{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d30e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyodbc\n",
    "# import pandas as pd\n",
    "\n",
    "# conn = pyodbc.connect(\n",
    "#     \"DRIVER={ODBC Driver 18 for SQL Server};\"\n",
    "#     \"SERVER=YUEFANG;\"\n",
    "#     \"DATABASE=adaptive rag;\"\n",
    "#     \"UID=rag_user;\"\n",
    "#     \"PWD=Haha100!;\"\n",
    "#     \"Encrypt=no;\"\n",
    "#     \"TrustServerCertificate=yes;\"\n",
    "# )\n",
    "\n",
    "# cursor = conn.cursor()\n",
    "# cursor.execute(\"SELECT @@VERSION\")\n",
    "# print(cursor.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1de2b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from [adaptive rag]..healthcare_dataset\"\n",
    "\n",
    "# cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "046c4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# healthcare = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2dcfc8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# healthcare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8007f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pyodbc\n",
    "from typing import List\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7210ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "\n",
    "OLLAMA_MODEL = \"llama3:8b\"\n",
    "\n",
    "SQL_CONN_STR = (\n",
    "    \"DRIVER={ODBC Driver 18 for SQL Server};\"\n",
    "    \"SERVER=YUEFANG;\"\n",
    "    \"DATABASE=adaptive rag;\"\n",
    "    \"UID=rag_user;\"\n",
    "    \"PWD=Haha100!;\"\n",
    "    \"Encrypt=no;\"\n",
    "    \"TrustServerCertificate=yes;\"\n",
    ")\n",
    "\n",
    "CHROMA_DIR = \"./schema_store\"\n",
    "\n",
    "TOP_K_SCHEMA = 5\n",
    "MAX_ROWS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ae085ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. LOAD SCHEMA FROM SQL SERVER\n",
    "# =========================\n",
    "\n",
    "def load_schema_from_db() -> List[Document]:\n",
    "    conn = pyodbc.connect(SQL_CONN_STR)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT\n",
    "            TABLE_SCHEMA,\n",
    "            TABLE_NAME,\n",
    "            COLUMN_NAME,\n",
    "            DATA_TYPE\n",
    "        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "        ORDER BY TABLE_SCHEMA, TABLE_NAME\n",
    "    \"\"\")\n",
    "\n",
    "    tables = {}\n",
    "    for schema, table, col, dtype in cursor.fetchall():\n",
    "        key = f\"{schema}.{table}\"\n",
    "        tables.setdefault(key, []).append(f\"- {col} ({dtype})\")\n",
    "\n",
    "    print(tables)\n",
    "\n",
    "    docs = []\n",
    "    for table, cols in tables.items():\n",
    "        content = f\"Table: {table}\\nColumns:\\n\" + \"\\n\".join(cols)\n",
    "        docs.append(Document(page_content=content))\n",
    "\n",
    "    conn.close()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "874847f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2. BUILD / LOAD VECTOR STORE\n",
    "# =========================\n",
    "\n",
    "def build_schema_store():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "\n",
    "    docs = load_schema_from_db()\n",
    "\n",
    "    vectordb = Chroma.from_documents(\n",
    "        docs,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=CHROMA_DIR\n",
    "    )\n",
    "    vectordb.persist()\n",
    "    return vectordb\n",
    "\n",
    "def load_schema_store():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    )\n",
    "    return Chroma(\n",
    "        persist_directory=CHROMA_DIR,\n",
    "        embedding_function=embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed00775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3. SQL SAFETY CHECKS\n",
    "# =========================\n",
    "\n",
    "def is_safe_sql(sql: str) -> bool:\n",
    "    sql_l = sql.lower()\n",
    "\n",
    "    forbidden = [\n",
    "        \"insert\", \"update\", \"delete\", \"drop\",\n",
    "        \"alter\", \"truncate\", \"exec\", \"merge\"\n",
    "    ]\n",
    "    if any(word in sql_l for word in forbidden):\n",
    "        return False\n",
    "\n",
    "    if not sql_l.strip().startswith(\"select\"):\n",
    "        return False\n",
    "\n",
    "    if re.search(r\"select\\s+\\*\", sql_l):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbab6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4. SQL GENERATION\n",
    "# =========================\n",
    "\n",
    "SQL_PROMPT = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are a senior data engineer.\n",
    "\n",
    "Generate ONE valid Microsoft SQL Server query.\n",
    "\n",
    "Rules:\n",
    "- SELECT statements only\n",
    "- Use TOP if result is not aggregated\n",
    "- No SELECT *\n",
    "- Use only tables and columns provided\n",
    "- Do not explain anything\n",
    "- Do not wrap in markdown\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Return SQL only.\n",
    "\"\"\")\n",
    "\n",
    "def generate_sql(llm, schema_context: str, question: str) -> str:\n",
    "    prompt = SQL_PROMPT.format(\n",
    "        schema=schema_context,\n",
    "        question=question\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36c12452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5. EXECUTE SQL\n",
    "# =========================\n",
    "\n",
    "def run_sql(sql: str):\n",
    "    conn = pyodbc.connect(SQL_CONN_STR)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(sql)\n",
    "    columns = [c[0] for c in cursor.description]\n",
    "    rows = cursor.fetchmany(MAX_ROWS)\n",
    "\n",
    "    conn.close()\n",
    "    return columns, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5d7fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6. MAIN PIPELINE\n",
    "# =========================\n",
    "\n",
    "def ask(question: str):\n",
    "    llm = ChatOllama(model=OLLAMA_MODEL, temperature=0)\n",
    "\n",
    "    try:\n",
    "        vectordb = load_schema_store()\n",
    "    except:\n",
    "        vectordb = build_schema_store()\n",
    "\n",
    "    schema_docs = vectordb.similarity_search(question, k=TOP_K_SCHEMA)\n",
    "    schema_context = \"\\n\\n\".join(d.page_content for d in schema_docs)\n",
    "\n",
    "    sql = generate_sql(llm, schema_context, question)\n",
    "    print(\"\\nGenerated SQL:\\n\", sql)\n",
    "\n",
    "    if not is_safe_sql(sql):\n",
    "        raise ValueError(\"Unsafe SQL generated\")\n",
    "\n",
    "    cols, rows = run_sql(sql)\n",
    "\n",
    "    print(\"\\nResult:\")\n",
    "    print(cols)\n",
    "    for r in rows:\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02512780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated SQL:\n",
      " SELECT TOP 5 patient_id, billing_amount\n",
      "FROM visits\n",
      "ORDER BY billing_amount DESC;\n",
      "\n",
      "Result:\n",
      "['patient_id', 'billing_amount']\n",
      "(8789, 49995.90234375)\n",
      "(9384, 49994.984375)\n",
      "(3256, 49985.97265625)\n",
      "(734, 49974.8046875)\n",
      "(3526, 49974.30078125)\n",
      "\n",
      "Generated SQL:\n",
      " SELECT TOP 1 patient_id, SUM(billing_amount) AS total_billing\n",
      "FROM visits\n",
      "GROUP BY patient_id\n",
      "ORDER BY total_billing DESC;\n",
      "\n",
      "Result:\n",
      "['patient_id', 'total_billing']\n",
      "(4096, 159668.2607421875)\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 7. RUN\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        q = input(\"\\nAsk a question (or 'exit'): \")\n",
    "        if q.lower() == \"exit\":\n",
    "            break\n",
    "        ask(q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2sql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
